{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie3j7Yzh1fDU",
    "outputId": "864c6f64-e625-4c9c-c764-00d8c6b11661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FNv7xBt1lgl",
    "outputId": "3c12ba13-fc9d-4cb9-de76-0ad56898a964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.28.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GDmXsCW61o0q",
    "outputId": "8b680990-ef08-4ee2-bf4c-d6f9c68bcb09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yW0GTnL01pVc",
    "outputId": "66efca87-b316-45e2-a462-ac3c5040c06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EITwsjg1q-H",
    "outputId": "73ab9fda-e26f-4a2f-cb4e-f98b3437a3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
      "Collecting openai\n",
      "  Downloading openai-1.57.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Downloading openai-1.57.1-py3-none-any.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.5\n",
      "    Uninstalling openai-1.54.5:\n",
      "      Successfully uninstalled openai-1.54.5\n",
      "Successfully installed openai-1.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIJMx2mZ1uTu"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Li5GDl-rztJS",
    "outputId": "1a851e8a-4e3f-41f5-f06f-c9367f226f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ7FIWlIzf31"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"/content/drive/MyDrive/muse_lab/open_key.txt\", \"r\") as file:\n",
    "    api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUB4BCOp1yuD"
   },
   "outputs": [],
   "source": [
    "# OpenAI API 키를 환경변수로 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS2akhee11Fd",
    "outputId": "25239ca5-e74c-4498-9ecc-f8717ba00c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Nice to meet you too. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# GPT 작동 테스트\n",
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"hi, nice to meet you\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "UNtcafPA14OV",
    "outputId": "b7c9004d-5c48-4a21-ef20-1392514d12fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://9cd5cd905ceb4e2967.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9cd5cd905ceb4e2967.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 모델 구성 저장\n",
    "model_layers = []\n",
    "preprocessing_steps = []\n",
    "\n",
    "# CNN 모델에 적합한 레이어 옵션\n",
    "layer_options = [\"Conv2D\", \"MaxPooling2D\", \"Flatten\", \"Dense\", \"Dropout\", \"BatchNormalization\"]\n",
    "\n",
    "\n",
    "# 글로벌 변수\n",
    "loaded_data = None\n",
    "\n",
    "# 데이터셋 불러오기 함수\n",
    "def load_dataset(dataset_name):\n",
    "    global loaded_data\n",
    "    if dataset_name == \"MNIST\":\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        loaded_data = (X_train, y_train, X_test, y_test)\n",
    "        return f\"{dataset_name} 데이터셋이 성공적으로 불러와졌습니다! ({X_train.shape[0]}개 학습 데이터)\"\n",
    "    else:\n",
    "        return \"지원되지 않는 데이터셋입니다.\"\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(apply_normalization, add_channel, one_hot_encode):\n",
    "    global loaded_data\n",
    "    if loaded_data is None:\n",
    "        return \"먼저 데이터셋을 불러오세요!\"\n",
    "\n",
    "    X_train, y_train, X_test, y_test = loaded_data\n",
    "\n",
    "    if apply_normalization:\n",
    "        X_train = X_train.astype('float32') / 255.0\n",
    "        X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "    if add_channel:\n",
    "        X_train = X_train[..., None]\n",
    "        X_test = X_test[..., None]\n",
    "\n",
    "    if one_hot_encode:\n",
    "        y_train = to_categorical(y_train, num_classes=10)\n",
    "        y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "    loaded_data = (X_train, y_train, X_test, y_test)\n",
    "    return \"전처리가 완료되었습니다!\"\n",
    "\n",
    "\n",
    "# 레이어 추가 함수\n",
    "def add_layer(layer_type, params):\n",
    "    try:\n",
    "        parsed_params = {}\n",
    "        if params.strip():\n",
    "            param_pairs = params.split(\",\")\n",
    "            for pair in param_pairs:\n",
    "                key, value = pair.split(\"=\")\n",
    "                parsed_params[key.strip()] = eval(value.strip())\n",
    "\n",
    "        model_layers.append((layer_type, parsed_params))\n",
    "        return generate_model_blocks(), \"레이어가 성공적으로 추가되었습니다!\"\n",
    "    except Exception as e:\n",
    "        return generate_model_blocks(), f\"에러 발생: {str(e)}\"\n",
    "\n",
    "# 모델 초기화 함수\n",
    "def reset_model():\n",
    "    global model_layers\n",
    "    model_layers = []\n",
    "    return generate_model_blocks(), \"모델이 초기화되었습니다.\"\n",
    "\n",
    "# HTML 기반 모델 블록 생성 함수\n",
    "def generate_model_blocks():\n",
    "    html = '''\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center; gap: 15px; padding: 20px;\">\n",
    "    '''\n",
    "    for idx, (layer_type, params) in enumerate(model_layers):\n",
    "        html += f\"\"\"\n",
    "        <div style=\"\n",
    "            border: 2px solid #2E2E2E;\n",
    "            background-color: #333333;\n",
    "            color: #EAEAEA;\n",
    "            padding: 20px;\n",
    "            margin: 10px;\n",
    "            width: 320px;\n",
    "            text-align: center;\n",
    "            border-radius: 12px;\n",
    "            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 3px 6px rgba(0, 0, 0, 0.15);\n",
    "        \">\n",
    "            <h3 style=\"margin: 0; color: #FFD700;\">{idx + 1}. {layer_type}</h3>\n",
    "            <p style=\"margin: 10px 0 0; font-size: 14px; line-height: 1.6;\">{params}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    html += '</div>'\n",
    "    return html\n",
    "\n",
    "# 코드 변환 함수\n",
    "def convert_to_code(epochs=5):\n",
    "    \"\"\"\n",
    "    AST를 기반으로 Keras 코드를 생성.\n",
    "    \"\"\"\n",
    "    code = \"from tensorflow.keras.models import Sequential\\n\"\n",
    "    code += \"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\\n\"\n",
    "    code += \"from tensorflow.keras.datasets import mnist\\nimport numpy as np\\n\\n\"\n",
    "\n",
    "    # 데이터 전처리 추가\n",
    "    code += \"# 데이터 로드 및 전처리\\n\"\n",
    "    code += \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\n\"\n",
    "    code += \"X_train = X_train.reshape(-1, 28, 28, 1)  # 4D 텐서로 변환\\n\"\n",
    "    code += \"X_test = X_test.reshape(-1, 28, 28, 1)\\n\"\n",
    "    code += \"X_train, X_test = X_train / 255.0, X_test / 255.0  # 정규화\\n\"\n",
    "\n",
    "    # 모델 정의 코드 추가\n",
    "    code += \"\\nmodel = Sequential()\\n\"\n",
    "    for layer_type, params in model_layers:\n",
    "        params_str = \", \".join([f\"{k}={v}\" for k, v in params.items()])\n",
    "        code += f\"model.add({layer_type}({params_str}))\\n\"\n",
    "\n",
    "    # 에포크 반영\n",
    "    code += f\"\"\"\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs={epochs}, validation_data=(X_test, y_test))\n",
    "    print(\"Training Complete. Final Accuracy:\", history.history['accuracy'][-1])\n",
    "    \"\"\"\n",
    "    return code.strip()  # Markdown 구문 제거\n",
    "\n",
    "\n",
    "\n",
    "# GPT API로 설명 요청\n",
    "def explain_model(model_code, train_results):\n",
    "    prompt = \"다음은 생성된 Keras 모델 코드와 학습 결과입니다:\\n\\n\"\n",
    "    prompt += \"### 모델 코드 ###\\n\"\n",
    "    prompt += model_code + \"\\n\\n\"\n",
    "    prompt += \"### 학습 결과 ###\\n\"\n",
    "    prompt += train_results + \"\\n\\n\"\n",
    "    prompt += \"위 내용을 바탕으로 이 모델의 구조와 성능 분석, 그리고 모델 튜닝 방법을 초보자가 이해할 수 있도록 설명해 주세요.\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                 \"content\": \"You are an expert in Python and Keras.\" + prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"GPT 요청 중 에러 발생: {str(e)}\"\n",
    "\n",
    "\n",
    "# GPT API로 코드 요청 및 반환\n",
    "def request_gpt_code(raw_code):\n",
    "    prompt = f\"다른 코멘트나 글은 절대 적지 않고 오직 요구하는 파이썬 코드만을 작성해주세요. 다음 Keras 코드를 데이터에 맞게 실행 가능한 형태로 수정해 주세요:\\n\\n{raw_code}. \"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                 \"content\": \"You are an expert in Python and Keras.\" + prompt}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"GPT 요청 중 에러 발생: {str(e)}\"\n",
    "\n",
    "\n",
    "# 모델 훈련 함수\n",
    "def train_model(gpt_code):\n",
    "    \"\"\"\n",
    "    GPT가 반환한 Keras 코드를 실행하여 학습.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = \"/content/model_training.py\"\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(gpt_code)\n",
    "\n",
    "        result = subprocess.check_output([\"python3\", file_path], stderr=subprocess.STDOUT, text=True)\n",
    "        return result\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"훈련 중 에러 발생:\\n{e.output}\"\n",
    "\n",
    "\n",
    "def get_last_two_sentences(output_text):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 마지막 두 문장을 반환.\n",
    "    \"\"\"\n",
    "    sentences = output_text.strip().split(\".\")\n",
    "    # 마지막 두 문장 추출 및 공백 제거\n",
    "    last_two = \". \".join(sentences[-3:]).strip()\n",
    "    return last_two if last_two else \"훈련 결과가 비어 있습니다.\"\n",
    "\n",
    "\n",
    "# Gradio UI 정의\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# CNN 노코드 AI 블록 모델 생성기\")\n",
    "\n",
    "    # 데이터셋 불러오기\n",
    "    dataset_dropdown = gr.Dropdown([\"MNIST\"], label=\"데이터셋 선택\")\n",
    "    load_button = gr.Button(\"데이터셋 불러오기\")\n",
    "    dataset_status = gr.Textbox(label=\"상태\", interactive=False)\n",
    "\n",
    "    load_button.click(load_dataset, inputs=dataset_dropdown, outputs=dataset_status)\n",
    "\n",
    "    # 전처리 옵션\n",
    "    gr.Markdown(\"### 전처리 옵션\")\n",
    "    apply_normalization = gr.Checkbox(label=\"Normalize (0~1로 스케일)\", value=True)\n",
    "    add_channel = gr.Checkbox(label=\"Add Channel Dimension (28x28 → 28x28x1)\", value=True)\n",
    "    one_hot_encode = gr.Checkbox(label=\"One-Hot Encode Labels\", value=True)\n",
    "\n",
    "    preprocess_button = gr.Button(\"전처리 실행\")\n",
    "    preprocess_status = gr.Textbox(label=\"전처리 상태\", interactive=False)\n",
    "\n",
    "    preprocess_button.click(preprocess_data, inputs=[apply_normalization, add_channel, one_hot_encode], outputs=preprocess_status)\n",
    "\n",
    "    # 모델 구성\n",
    "    layer_type = gr.Dropdown(choices=layer_options, label=\"레이어 타입\")\n",
    "    params_input = gr.Textbox(label=\"매개변수 (예: filters=32, kernel_size=(3,3), activation='relu')\")\n",
    "    add_layer_button = gr.Button(\"레이어 추가\")\n",
    "    reset_model_button = gr.Button(\"모델 초기화\")\n",
    "    model_blocks = gr.HTML()\n",
    "\n",
    "    # 에포크 입력 필드\n",
    "    epochs_input = gr.Number(label=\"훈련 에포크 수\", value=5)  # 기본값 5\n",
    "\n",
    "\n",
    "    # 코드 생성 및 GPT 요청, 훈련\n",
    "    generate_code_button = gr.Button(\"코드 생성\")\n",
    "    code_output = gr.Code(label=\"Keras 코드\")\n",
    "    gpt_request_button = gr.Button(\"GPT 사용하여 실행 가능한 코드로 변환\")\n",
    "    gpt_code_output = gr.Code(label=\"GPT 변환 코드\")\n",
    "    train_model_button = gr.Button(\"모델 학습\")\n",
    "    train_output = gr.Textbox(label=\"훈련 결과\")\n",
    "\n",
    "\n",
    "    # GPT와의 연결 및 코드 생성\n",
    "    explain_button = gr.Button(\"모델 설명 및 성능 분석\")\n",
    "    explanation_output = gr.Textbox(label=\"GPT 설명\")\n",
    "\n",
    "    # 레이어 추가 버튼 동작\n",
    "    add_layer_button.click(\n",
    "        fn=add_layer,\n",
    "        inputs=[layer_type, params_input],\n",
    "        outputs=[model_blocks]\n",
    "    )\n",
    "\n",
    "    reset_model_button.click(\n",
    "        fn=reset_model,\n",
    "        outputs=[model_blocks]\n",
    "    )\n",
    "\n",
    "    # 코드 생성 버튼 동작 수정\n",
    "    generate_code_button.click(\n",
    "    fn=lambda epochs: convert_to_code(epochs),  # 에포크 전달\n",
    "    inputs=epochs_input,  # 에포크 입력 필드 추가\n",
    "    outputs=code_output\n",
    ")\n",
    "\n",
    "    # GPT 코드 요청 버튼 동작\n",
    "    gpt_request_button.click(\n",
    "        fn=request_gpt_code,\n",
    "        inputs=code_output,\n",
    "        outputs=gpt_code_output\n",
    "    )\n",
    "\n",
    "    # 모델 학습 버튼 동작\n",
    "    train_model_button.click(\n",
    "        fn=train_model,\n",
    "        inputs=gpt_code_output,\n",
    "        outputs=train_output\n",
    "    )\n",
    "\n",
    "    # GPT 설명 요청\n",
    "    explain_button.click(\n",
    "        fn=lambda code, train: explain_model(code, get_last_two_sentences(train)),\n",
    "        inputs=[gpt_code_output, train_output],  # gpt_code_output과 축약된 train_output 전달\n",
    "        outputs=explanation_output\n",
    "    )\n",
    "\n",
    "    # 코드 생성 버튼 동작 수정\n",
    "    generate_code_button.click(\n",
    "    fn=lambda epochs: convert_to_code(epochs),  # 에포크 전달\n",
    "    inputs=epochs_input,  # 에포크 입력 필드 추가\n",
    "    outputs=code_output\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
